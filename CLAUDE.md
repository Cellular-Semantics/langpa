# Development Rules

## Test-Driven Development (MANDATORY)
1. Write unit and integration tests FIRST
2. Tests must fail initially (red)
3. Commit tests before implementation
4. Write minimal code to pass tests (green)
5. Refactor while keep**ing tests green, commit

## TDD Workflow Commands (using uv)
```bash
# Install dependencies and sync environment
uv sync --dev            # Install all dependencies including dev tools

# Run tests
uv run pytest                    # All tests
uv run pytest -m unit           # Unit tests only
uv run pytest -m integration    # Integration tests only
uv run pytest --cov             # With coverage

# Documentation (run before committing!)
python scripts/check-docs.py         # Build docs and check for errors
cd docs && uv run sphinx-build . _build/html -W  # Alternative direct command

# Add new dependencies
uv add requests              # Add runtime dependency
uv add --dev pytest         # Add development dependency

# Environment management
uv sync                      # Sync dependencies (production only)
uv sync --dev               # Sync with development dependencies
```

## Code Quality Strategy (temporarily relaxed)
- Ruff lint/format and mypy type checks are temporarily disabled to speed development.
- Pre-commit hooks and CI do not enforce lint/type checks during this period.

## Environment Configuration
- **ALWAYS use dotenv**: Use `from dotenv import load_dotenv; load_dotenv()` for environment variables, never use `os.getenv()` directly
- **Never hardcode secrets**: All API keys, emails, and sensitive data must come from .env files
- **Environment precedence**: Constructor params > environment variables > sensible defaults

## FORBIDDEN Patterns
- Mock data generation for integration tests
- Simulated API responses
- Dummy database connections
- Placeholder implementations
- Integration tests that pass without real integration
- Skipping failing tests with pytest.mark.skip

## Required Test Structure
- Unit tests: tests/unit/ (fast, isolated, no external deps)
- Integration tests: tests/integration/ (environment-dependent behavior)
- Fixtures with real connection setup/teardown
- Coverage minimum: 80%
- All tests must use pytest markers (@pytest.mark.unit or @pytest.mark.integration)

## Integration Testing Strategy
**Local Development (Real APIs Only):**
- Integration tests REQUIRE real API keys (e.g. OPENAI_API_KEY, ANTHROPIC_API_KEY)
- Tests FAIL HARD if no API keys are present
- Forces developers to test against real APIs before pushing
- Pre-commit hooks enforce integration test passage
- Command: `uv run pytest -m integration`

**CI/GitHub Actions (Unit Tests Only):**
- NO integration tests run in CI to avoid mock complexity
- Only unit tests run (fast, no external dependencies)
- Command: `uv run pytest -m unit`

**Rationale:**
- Local: Mandatory real API testing ensures integration quality
- CI: Simple, fast, reliable unit test validation
- Avoids complex mock maintenance and false confidence
- Forces developers to have working API access

## Documentation Requirements
- Google-style docstrings for all public functions/classes
- **RST syntax in docstrings**: Use `.. code-block:: python` instead of markdown ```python
- Auto-generated API docs via Sphinx + AutoAPI
- Manual docs in docs/ using MyST markdown
- Build docs: `python scripts/check-docs.py` (recommended) or `sphinx-build docs docs/_build`
- **Always run docs check before committing** to catch RST syntax errors

## MVP Definition
For each feature:
1. Clear, testable goal
2. Integration test demonstrating real API connection
3. Error handling for actual failure modes (network, malformed data, rate limits)
4. No feature complete until real integration test passes

## Planning

Each proposed plan of work should include an MVP and a critique section detailing potential issues/risks with the approach.

Before developing a plan, make sure you fully understand whether the imported libraries support the functions you are proposing. It is important not to duplicate core functionality.

## Architecture

Use cellsem-llm-client for agents.
Use deepsearch-client for deepsearch (deepsearch calls belong in services)

### Schema first pattern:
 - Schema is ALWAYS defined as JSON schema NOT pydantic schema.
 - pydantic models are ALWAYS derived from JSON schema - using cellsem-llm-client
 - All JSON schema content generated by agents/deepsearch is validated and corrected by pydantic 
 - where schema specified additionalFields: False, pydantic must be set to drop any additional fields with a warning rather than hard failing.
 - JSON schema should be modular with modules strictly separating business logic from biology

### Orchestration:
 - Agents are orchestrated via pydanticAI graphs

### Declarative workflows:
 - As far as possible, prefer declarative structure:
    - Prompts (including system prompts) + interpolation defined in YAML
    - YAML files define preset combinations:  prompts, provider model, other API metadata (keys and values)
    - If declarative use systems for orchestration via pydanticAI graphs are possible, then please use and document them.

### Transparency:
 - It must be possible to save and inspect intermediate files in workflows
 - It must be possible to run workflows starting from multiple steps

### Scripts:
 - All workflows should have a core runner script supporting:
   - single run
   - batch mode
   - dry-run (a single run returning a report of all prompts, agents, API calls in order.)
 - The runner script must be distributed with the package
 - Be careful to avoid encoding workflows in scripts rather than in the core package.

### Repo structure:
The repo must consist of two packages: A core package + a validation package. Where relevant these MUST share schemas. They MUST also share an outputs directory and standard ways to structure these.  For example, outputs/{project}/{query}/{timestamp}/(results_files).

Validation package must
be capable of basic stats - precision, recall, F1, ROC curves, heat map bubble plots...